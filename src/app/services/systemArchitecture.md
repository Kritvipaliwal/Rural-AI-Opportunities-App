# GramRakshak AI - Complete System Architecture

## ğŸ—ï¸ System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GRAMRAKSHAK AI ECOSYSTEM                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Mobile App â”‚â—„â”€â”€â”€â”¤  API Gateway â”‚â—„â”€â”€â”€â”¤  Load Balancerâ”‚         â”‚
â”‚  â”‚  (React PWA) â”‚    â”‚   (FastAPI)  â”‚    â”‚    (Nginx)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                    â”‚                                       â”‚
â”‚         â”‚                    â–¼                                       â”‚
â”‚         â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚         â”‚         â”‚   Microservices      â”‚                          â”‚
â”‚         â”‚         â”‚   Architecture       â”‚                          â”‚
â”‚         â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                    â”‚                                       â”‚
â”‚         â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚         â”‚         â”‚                     â”‚                           â”‚
â”‚         â–¼         â–¼                     â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  CDN    â”‚  â”‚ AI/ML   â”‚         â”‚ Backend â”‚                      â”‚
â”‚  â”‚ (Media) â”‚  â”‚ Engine  â”‚         â”‚ Servicesâ”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                    â”‚                     â”‚                           â”‚
â”‚                    â–¼                     â–¼                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚         â”‚  GPU Cluster     â”‚  â”‚   Databases      â”‚                 â”‚
â”‚         â”‚  (ML Training)   â”‚  â”‚ (PostgreSQL,     â”‚                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  MongoDB, Redis) â”‚                â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Flow Architecture

### 1. Document Verification Pipeline

```
User Upload â†’ OCR Engine â†’ Fraud Detection ML â†’ Database Verification â†’ Trust Score
     â”‚             â”‚              â”‚                      â”‚                  â”‚
     â”‚             â–¼              â–¼                      â–¼                  â–¼
  [Image]    [Tesseract/     [CNN Model          [DigiLocker API]    [Weighted
             Google Vision]   ResNet-50]          [UIDAI API]         Algorithm]
                                                                           â”‚
                                                                           â–¼
                                                                    QR Certificate
                                                                    Blockchain Hash
```

**Technical Stack:**
- OCR: Tesseract 5.0 / Google Cloud Vision API
- Fraud Detection: Custom CNN trained on 100K+ documents
- Verification APIs: DigiLocker, UIDAI Aadhaar API, Income Tax API
- QR Generation: qrcode library + blockchain (Hyperledger Fabric)
- Storage: AWS S3 for images, PostgreSQL for metadata

**AI Model Details:**
```python
# Document Fraud Detection Model
Model: ResNet-50 (Fine-tuned)
Input: 224x224 RGB Image
Layers: 
  - Convolutional Layers (50 layers)
  - Global Average Pooling
  - Dense (512 units, ReLU)
  - Dropout (0.5)
  - Output (3 units - Real/Fake/Suspicious, Softmax)
Training Data: 150K annotated documents
Accuracy: 94.7%
Inference Time: ~500ms on CPU
```

### 2. Message Scam Detection Pipeline

```
User Input â†’ Text Preprocessing â†’ NLP Analysis â†’ Pattern Matching â†’ Verdict
    â”‚              â”‚                   â”‚               â”‚              â”‚
    â”‚              â–¼                   â–¼               â–¼              â–¼
[WhatsApp]    [Cleaning,          [BERT Model]    [Regex Rules]  [REAL/FAKE
  [SMS]        Tokenization]      [Sentiment      [URL Check]    /SUSPICIOUS]
                                   Analysis]       [Domain Auth]
                                       â”‚
                                       â–¼
                               [Scam Database
                                Lookup - Redis]
```

**Technical Stack:**
- NLP Model: DistilBERT (multilingual) fine-tuned for scam detection
- URL Verification: Custom API hitting phishing databases
- Pattern Matching: Regex + Aho-Corasick algorithm
- Database: Redis for fast scam pattern lookup
- Real-time: WebSocket for instant alerts

**NLP Model Architecture:**
```python
# Scam Detection NLP Model
Model: DistilBERT (Multilingual)
Layers:
  - Tokenization (BERT Tokenizer)
  - Embedding (768 dim)
  - Transformer Layers (6 layers)
  - Classification Head
  - Output (Binary - Scam/Not Scam)
Training: 500K SMS/WhatsApp messages (scraped + crowdsourced)
Languages: Hindi, English, Hinglish
Accuracy: 91.2%
Inference: ~200ms
```

### 3. Scheme Crawler & Updater Pipeline

```
Govt Websites â†’ Web Scraper â†’ Data Normalizer â†’ ML Classifier â†’ Database
     â”‚              â”‚              â”‚                  â”‚              â”‚
     â”‚              â–¼              â–¼                  â–¼              â–¼
[pmkisan.gov] [Scrapy/       [Cleaning,         [Scheme Type    [PostgreSQL]
[pmjay.gov]    Selenium]      Deduplication]     Classifier]     [Elasticsearch]
[myscheme.in]                                                         â”‚
                                                                      â–¼
                                                                  Push Updates
                                                                  via WebSocket
```

**Technical Stack:**
- Crawler: Scrapy + Selenium for dynamic content
- Scheduler: Apache Airflow (runs daily)
- Storage: PostgreSQL + Elasticsearch for full-text search
- Real-time: WebSocket server (Socket.io)
- Notifications: FCM (Firebase Cloud Messaging)

**Crawler Configuration:**
```python
# Scheme Crawler Bot
Frequency: Every 6 hours
Sources: 45+ government websites
Extraction:
  - Scheme name (XPath/CSS selectors)
  - Eligibility criteria
  - Deadline dates
  - Documents required
  - Official URLs
Deduplication: Fuzzy string matching (fuzzywuzzy)
Classification: Random Forest (scheme category)
Output: JSON â†’ PostgreSQL
```

### 4. Application Form Generator Pipeline

```
Scheme Selection â†’ User Profile Fetch â†’ PDF Template â†’ Auto-fill â†’ QR Code â†’ Output
      â”‚                 â”‚                    â”‚             â”‚           â”‚         â”‚
      â–¼                 â–¼                    â–¼             â–¼           â–¼         â–¼
[Scheme ID]      [User Database]      [LaTeX/         [jsPDF/      [QR Gen]  [PDF File]
                 [DigiLocker API]      ReportLab]     PDFKit]                [Checklist]
```

**Technical Stack:**
- PDF Generation: ReportLab (Python) / jsPDF (JS)
- Template Engine: Jinja2 for dynamic fields
- Auto-fill: DigiLocker API + User Profile Database
- QR Code: Application tracking ID embedded
- Storage: AWS S3, CDN for downloads

**Form Generation Logic:**
```python
# Auto Form Generator
def generate_application(scheme_id, user_id):
    # Step 1: Fetch scheme template
    template = get_scheme_template(scheme_id)
    
    # Step 2: Fetch user data
    user_data = get_user_profile(user_id)
    digilocker_data = fetch_digilocker(user_id)
    
    # Step 3: Map fields
    filled_data = map_fields(template, user_data, digilocker_data)
    
    # Step 4: Generate PDF
    pdf = generate_pdf(template, filled_data)
    
    # Step 5: Create checklist
    checklist = generate_checklist(template.documents)
    
    # Step 6: Generate QR for tracking
    qr_code = generate_qr(application_id)
    
    return {
        'pdf_url': upload_to_s3(pdf),
        'checklist': checklist,
        'qr_code': qr_code
    }
```

### 5. SMS Gateway Integration

```
User SMS â†’ Twilio/MSG91 â†’ Webhook â†’ AI Processing â†’ Response Generation â†’ SMS Reply
    â”‚           â”‚            â”‚           â”‚                  â”‚                  â”‚
    â”‚           â–¼            â–¼           â–¼                  â–¼                  â–¼
[Feature]  [Receive]    [FastAPI]   [NLP Model]       [Template]         [Send SMS]
[Phone]                 [Endpoint]  [Redis Cache]      [Jinja2]          [Twilio API]
```

**SMS Flow:**
```
Incoming: User sends "VERIFY <message>" to shortcode 9XXXXXXX
Processing:
  1. Webhook receives SMS
  2. Extract message content
  3. Run scam detection
  4. Generate response
  5. Send reply SMS
Response: "âœ“ SAFE - This is an official government message" OR
         "âš  SUSPICIOUS - Do not click any links. Report to 1930"
```

**Technical Implementation:**
```python
# SMS Webhook Handler
@app.post("/sms/webhook")
async def handle_sms(request: SMSWebhook):
    phone = request.from_number
    message = request.body
    
    # AI Processing
    result = await nlp_scam_detector.predict(message)
    
    # Generate response
    if result.verdict == "FAKE":
        response = f"âš  FRAUD ALERT\n{message[:50]}...\nDO NOT respond. Report: 1930"
    else:
        response = f"âœ“ SAFE MESSAGE\nConfidence: {result.confidence}%"
    
    # Send reply
    await sms_gateway.send(phone, response)
    
    # Log
    await db.log_sms_check(phone, message, result)
```

### 6. Village Risk Heatmap System

```
Fraud Reports â†’ Aggregator â†’ Risk Scorer â†’ Heatmap Generator â†’ Real-time Update
      â”‚            â”‚             â”‚              â”‚                      â”‚
      â–¼            â–¼             â–¼              â–¼                      â–¼
[Location]   [PostgreSQL]   [ML Model -    [GeoJSON]            [WebSocket
[Timestamp]  [Analytics]     Random         [Leaflet.js]         Broadcasting]
[Type]                       Forest]        [Color Coding]
```

**Risk Scoring Algorithm:**
```python
# Risk Score Calculation
def calculate_village_risk(village_id, time_window='30d'):
    reports = get_fraud_reports(village_id, time_window)
    
    # Weighted scoring
    score = 0
    for report in reports:
        weight = {
            'phishing': 2,
            'fake_scheme': 3,
            'document_fraud': 4,
            'impersonation': 5
        }[report.type]
        
        # Decay factor (recent = higher weight)
        days_old = (datetime.now() - report.timestamp).days
        decay = exp(-0.05 * days_old)
        
        score += weight * decay
    
    # Normalize to 0-100
    risk_score = min(100, score * 5)
    
    # Categorize
    if risk_score < 30:
        risk_level = 'low'
    elif risk_score < 70:
        risk_level = 'medium'
    else:
        risk_level = 'high'
    
    return {
        'score': risk_score,
        'level': risk_level,
        'total_reports': len(reports)
    }
```

### 7. Voice Assistant Architecture

```
Voice Input â†’ STT â†’ Language Detection â†’ Intent Recognition â†’ Query Processing â†’ TTS â†’ Audio Output
     â”‚         â”‚          â”‚                      â”‚                   â”‚             â”‚         â”‚
     â–¼         â–¼          â–¼                      â–¼                   â–¼             â–¼         â–¼
[Mic]    [Whisper/   [fastText]            [Rasa NLU]         [RAG System]  [gTTS/       [Speaker]
         Google                                                [Vector DB]   Azure TTS]
         Speech]                                               [Pinecone]
```

**Voice Processing Stack:**
- STT: OpenAI Whisper (multilingual) / Google Speech-to-Text
- Language Detection: fastText model
- Intent Recognition: Rasa NLU framework
- Query Processing: RAG (Retrieval-Augmented Generation)
  - Vector DB: Pinecone (govt scheme embeddings)
  - LLM: GPT-4 / LLaMA 2 (fine-tuned on Hindi)
- TTS: Google Text-to-Speech / Azure TTS (regional voices)

**RAG Implementation:**
```python
# Voice Query RAG System
async def process_voice_query(audio_blob, language):
    # Step 1: Speech to Text
    text = await whisper_stt(audio_blob, language)
    
    # Step 2: Intent Recognition
    intent = await rasa_nlu.parse(text)
    
    # Step 3: Retrieve relevant documents
    query_embedding = await embed_text(text)
    relevant_docs = await pinecone.query(
        vector=query_embedding,
        top_k=5,
        filter={"language": language}
    )
    
    # Step 4: Generate response using LLM
    context = "\n".join([doc.text for doc in relevant_docs])
    prompt = f"""
    Context: {context}
    Question: {text}
    Answer in {language}:
    """
    response = await llm.generate(prompt)
    
    # Step 5: Text to Speech
    audio_response = await tts(response, language, voice='female')
    
    return {
        'text': response,
        'audio_url': upload_audio(audio_response)
    }
```

## ğŸ—„ï¸ Database Schema

### PostgreSQL Tables

```sql
-- Users Table
CREATE TABLE users (
    id UUID PRIMARY KEY,
    phone VARCHAR(15) UNIQUE NOT NULL,
    name VARCHAR(100),
    language VARCHAR(5) DEFAULT 'hi',
    village_id UUID,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Documents Table
CREATE TABLE documents (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    document_type VARCHAR(50),
    file_url TEXT,
    trust_score INTEGER,
    status VARCHAR(20),
    verified_at TIMESTAMP,
    qr_code TEXT,
    blockchain_hash TEXT
);

-- Schemes Table
CREATE TABLE schemes (
    id UUID PRIMARY KEY,
    title VARCHAR(200),
    title_hi VARCHAR(200),
    category VARCHAR(50),
    deadline DATE,
    amount VARCHAR(100),
    eligibility JSONB,
    documents JSONB,
    official_url TEXT,
    last_updated TIMESTAMP
);

-- Fraud Reports Table
CREATE TABLE fraud_reports (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    village_id UUID,
    fraud_type VARCHAR(50),
    description TEXT,
    evidence_url TEXT,
    status VARCHAR(20),
    reported_at TIMESTAMP
);

-- Message Checks Table
CREATE TABLE message_checks (
    id UUID PRIMARY KEY,
    user_id UUID,
    message_text TEXT,
    verdict VARCHAR(20),
    confidence FLOAT,
    checked_at TIMESTAMP
);
```

### Redis Cache Structure

```
# Scam patterns cache
scam_patterns:{pattern_id} â†’ {pattern, score, last_seen}

# User sessions
user_session:{user_id} â†’ {language, preferences, last_activity}

# Scheme cache (TTL: 6 hours)
scheme:{scheme_id} â†’ {full scheme JSON}

# Rate limiting
rate_limit:{ip_address} â†’ {request_count, reset_time}
```

## ğŸ” Security & Compliance

### Data Protection
- Encryption at rest: AES-256
- Encryption in transit: TLS 1.3
- PII data: Tokenized (Aadhaar, Bank details)
- Compliance: IT Act 2000, DPDP Act 2023

### API Security
- Authentication: JWT tokens (15-min expiry)
- Rate limiting: 100 requests/min per IP
- API Gateway: Kong with OAuth 2.0
- DDoS protection: Cloudflare

### Blockchain Integration
```
Document Verification Certificate:
â”œâ”€â”€ Certificate ID (UUID)
â”œâ”€â”€ User ID (hashed)
â”œâ”€â”€ Document Hash (SHA-256)
â”œâ”€â”€ Timestamp
â”œâ”€â”€ Issuer Signature
â””â”€â”€ Blockchain Hash (Hyperledger Fabric)

Verification:
QR Scan â†’ Extract Hash â†’ Query Blockchain â†’ Validate â†’ Display Status
```

## ğŸ“ˆ Scalability Design

### Load Handling
- Expected Load: 10M users, 500K daily active
- API Capacity: 10,000 requests/second
- Database: Read replicas (5x), Write master (1x)
- CDN: CloudFront (images, PDFs, audio)
- Auto-scaling: Kubernetes (3-50 pods)

### Caching Strategy
```
L1: Browser Cache (PWA) - 24h
L2: CDN Cache (Cloudflare) - 1h
L3: Redis Cache - 30min
L4: Database Query - Real-time
```

## ğŸ”„ Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Kubernetes Cluster (EKS)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Frontend   â”‚    â”‚  Backend   â”‚       â”‚
â”‚  â”‚ (React)    â”‚    â”‚  (FastAPI) â”‚       â”‚
â”‚  â”‚ 5 Pods     â”‚    â”‚  10 Pods   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ AI/ML      â”‚    â”‚ Worker     â”‚       â”‚
â”‚  â”‚ Service    â”‚    â”‚ Queue      â”‚       â”‚
â”‚  â”‚ 3 Pods     â”‚    â”‚ (Celery)   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         External Services                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ AWS S3 (Storage)                       â”‚
â”‚ â€¢ AWS RDS (PostgreSQL)                   â”‚
â”‚ â€¢ AWS ElastiCache (Redis)                â”‚
â”‚ â€¢ Cloudflare (CDN + DDoS)                â”‚
â”‚ â€¢ Twilio (SMS Gateway)                   â”‚
â”‚ â€¢ Firebase (Push Notifications)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Performance Metrics

- API Response Time: <200ms (p95)
- Document Verification: <3s
- Message Check: <1s
- Voice Query: <2s
- App Load Time: <1.5s (3G network)
- Offline Mode: Full functionality for 48h

## ğŸ“± Offline Capabilities

- Service Worker: Cache API responses
- IndexedDB: Store user data, schemes, certificates
- Background Sync: Queue actions when online
- SMS Fallback: Works without internet

---

**Last Updated:** December 27, 2024
**Version:** 1.0.0
**Maintained by:** GramRakshak Development Team
